{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609b9cf0",
   "metadata": {},
   "source": [
    "## About this Project\n",
    "This project will predict Choronic Kidney Disease. Using UCI Machine Learning CKD dataset to train the model and predict the accuracy. Here I use LR, SVM, RF, DT, KNN and NB supervised classifier model to build our model.\n",
    "# üìö 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda52010",
   "metadata": {},
   "source": [
    "# ML libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795ce74",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6ed89",
   "metadata": {},
   "source": [
    "## üì• 2. Loading the Dataset\n",
    "Load the CKD dataset and show the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_model.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2d38e",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "# Context\n",
    "This dataset is originally from UCI Machine Learning Repository. The objective of the dataset is to diagnostically predict whether a patient is having chronic kidney disease or not, based on certain diagnostic measurements included in the dataset.\n",
    "\n",
    "# Content\n",
    "The datasets consists of several medical predictor variables and one target variable, Class. Predictor variables includes Blood Pressure(Bp), Albumin(Al), etc.\n",
    "## üìä 3. Basic Data Overview\n",
    "We now inspect the shape, missing values, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63add331",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data:\", data.shape)\n",
    "print(\"\\nMissing values per column:\\n\", data.isnull().sum())\n",
    "print(\"\\nData Types:\\n\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd2f5ec",
   "metadata": {},
   "source": [
    "There is no null value so do not need to replace or remove null value operation. To remove null value we can replace that value using mean value if the value is categoruical then change with the mode.\n",
    "\n",
    "Also there all columns contain numerical value so do not need to transfer any column datatype. If there is any categorical data then we can do 2 type encoding One is level encpding and another is one hot encoding. \n",
    "\n",
    "## üîç 4. Check for Duplicate Records\n",
    "Identify if there are any duplicated rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296560bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_duplicates = data[data.duplicated()]\n",
    "print(\"Number of duplicate rows:\", data_duplicates.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaf237",
   "metadata": {},
   "source": [
    "## üî• 5. Correlation Heatmap\n",
    "Visualizing correlations among features using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0764e",
   "metadata": {},
   "source": [
    "## üì¶ 6. Box Plot to Visualize Outliers\n",
    "Box plots help identify outliers in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d34a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.box(figsize=(15, 6), rot=90)\n",
    "plt.title(\"Boxplot of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90dec7b",
   "metadata": {},
   "source": [
    "## üö® 7. Detecting Outliers Using IQR Method\n",
    "Check for outlier indices in each numeric feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6753031",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data.drop(\"Class\", axis=1)\n",
    "\n",
    "def detect_outlier(feature):\n",
    "    Q1 = feature.quantile(0.25)\n",
    "    Q3 = feature.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return feature.index[(feature < lower_bound) | (feature > upper_bound)].tolist()\n",
    "\n",
    "for col in db:\n",
    "    print(f\"{col} --> {detect_outlier(data[col])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7800f",
   "metadata": {},
   "source": [
    "## üì¶ 8. Boxplot After Outlier Detection\n",
    "Visualizing boxplots again for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8cef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot.box(figsize=(15, 6), rot=90)\n",
    "plt.title(\"Boxplot After Outlier Detection\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0448d",
   "metadata": {},
   "source": [
    "## üö® 7. Detecting Outliers Using IQR Method\n",
    "Check for outlier indices in each numeric feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e159ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data.drop(\"Class\", axis=1)\n",
    "\n",
    "def detect_outlier(feature):\n",
    "    Q1 = feature.quantile(0.25)\n",
    "    Q3 = feature.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return feature.index[(feature < lower_bound) | (feature > upper_bound)].tolist()\n",
    "\n",
    "for col in db:\n",
    "    print(f\"{col} --> {detect_outlier(data[col])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33deb5f1",
   "metadata": {},
   "source": [
    "## üì¶ 8. Boxplot After Outlier Detection\n",
    "Visualizing boxplots again for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e90bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot.box(figsize=(15, 6), rot=90)\n",
    "plt.title(\"Boxplot After Outlier Detection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710ebcf",
   "metadata": {},
   "source": [
    "## üìà 9. Histogram of Features\n",
    "Distribution of each feature to understand data spread and skewness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.hist(figsize=(16, 12), bins=20, edgecolor='black')\n",
    "plt.suptitle('Histograms of Features', fontsize=16)\n",
    "plt.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d48db7c",
   "metadata": {},
   "source": [
    "## üåä 10. KDE (Kernel Density Estimation) Plots\n",
    "Visualizing the density distribution of each feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22029bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.plot(kind='density', subplots=True, layout=(4, 4), sharex=False, figsize=(16, 12))\n",
    "plt.suptitle('KDE Plots of Features', fontsize=16)\n",
    "plt.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257c2d9",
   "metadata": {},
   "source": [
    "## üîó 11. Pairplot of Selected Features\n",
    "Checking relationships between first 5 features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cefbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = db.columns[:5]\n",
    "sns.pairplot(db[selected_cols].copy())\n",
    "plt.suptitle('Pairplot of Selected Features', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2058d8a",
   "metadata": {},
   "source": [
    "## üìä 12. Class Distribution\n",
    "Visualizing how many instances belong to each CKD class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Class' in data.columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='Class', data=data, order=data['Class'].value_counts().index)\n",
    "    plt.title('Class Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee9a742",
   "metadata": {},
   "source": [
    "## üß¨ 13. Violin Plots of Features by CKD Class\n",
    "Detailed view of distributions for each feature across CKD classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns[:-1]:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.violinplot(x='Class', y=col, data=data, inner='quartile')\n",
    "    plt.title(f'Violin Plot of {col} by Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf936df",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 14. Data Preprocessing\n",
    "Split data, scale features, and prepare for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc05c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels if not already numerical\n",
    "if data['Class'].dtype == 'object':\n",
    "    data['Class'] = data['Class'].astype('category').cat.codes\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2265a",
   "metadata": {},
   "source": [
    "## ü§ñ 15. Train Multiple Classifiers\n",
    "We will train Logistic Regression, SVM, Decision Tree, KNN, Naive Bayes, and Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nüß† {name} Accuracy: {acc:.2f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54dbd6",
   "metadata": {},
   "source": [
    "## üèÅ Summary\n",
    "This notebook walked through loading, visualizing, preprocessing, and classifying Chronic Kidney Disease data using several ML algorithms. You can improve results further using hyperparameter tuning, feature selection, or ensemble models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
